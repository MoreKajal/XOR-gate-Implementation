{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of XORgateusingNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1t2aGfCm5GrOHCsleVUn2y4ofNyzvAojV",
      "authorship_tag": "ABX9TyMSmglCcyTR/+vdQkX9vmRT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoreKajal/XOR-gate-Implementation/blob/main/Copy_of_XORgateusingNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFrCVL9oJolM"
      },
      "source": [
        "***Implementing XOR gate using BackPropagation in NN***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yBool3DLrIw"
      },
      "source": [
        "import numpy as np\r\n",
        "import time\r\n",
        "#np.random.seed(0)\r\n",
        "\r\n",
        "start_time = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5ETjQAWLr65"
      },
      "source": [
        "*Define Sigmoid Activation and Gradient Descent function*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUTm7-47NNAs"
      },
      "source": [
        "def sigmoid (x):\r\n",
        "  return 1/( 1 + np.exp(-x))\r\n",
        "\r\n",
        "def sigmoid_derivative(x):\r\n",
        "  return x * ( 1 - x )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpy7T9ECLr4Q"
      },
      "source": [
        "*Define Input data and Expected Output*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwEPIp9XObDz"
      },
      "source": [
        "inputs = np.array([[0,0], [0,1], [1,0], [1,1]])\r\n",
        "expected_output = np.array([[0], [1], [1], [0]])\r\n",
        "\r\n",
        "epochs=10000\r\n",
        "lr=0.5\r\n",
        "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP0drXCpPI_9"
      },
      "source": [
        "*Initialize Random Weights and Bias*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv0TiulqPPc5",
        "outputId": "03271c95-b245-4d00-937a-2d86e2d75796"
      },
      "source": [
        "hidden_wts = np.random.uniform(size = (inputLayerNeurons, hiddenLayerNeurons))\r\n",
        "hidden_bias = np.random.uniform(size = (1, hiddenLayerNeurons))\r\n",
        "\r\n",
        "output_wts = np.random.uniform(size = (hiddenLayerNeurons, outputLayerNeurons))\r\n",
        "output_bias = np.random.uniform(size = (1, outputLayerNeurons))\r\n",
        "\r\n",
        "print(\"Initial Hidden Weights: \", end= '')\r\n",
        "print(*hidden_wts)\r\n",
        "print(\"Initial Hidden biases: \", end= '')\r\n",
        "print(*hidden_bias)\r\n",
        "print(\"Initial Output Weights: \", end= '')\r\n",
        "print(*output_wts)\r\n",
        "print(\"Initial output biases: \", end= '')\r\n",
        "print(*output_bias)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Hidden Weights: [0.11207471 0.6130985 ] [0.50016605 0.66728977]\n",
            "Initial Hidden biases: [0.46704008 0.74125497]\n",
            "Initial Output Weights: [0.04885567] [0.70703665]\n",
            "Initial output biases: [0.94182797]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHZDUwXcQ6Q2"
      },
      "source": [
        "*Training Algorithm*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITjlcEISQ-gN",
        "outputId": "16c3c12a-ff5e-4763-b99a-9916b7010810"
      },
      "source": [
        "for _ in range(epochs):\r\n",
        "  #Forward Propagation\r\n",
        "  hidden_layer_activation = np.dot(inputs, hidden_wts)\r\n",
        "  hidden_layer_activation += hidden_bias\r\n",
        "  hidden_layer_output = sigmoid(hidden_layer_activation)\r\n",
        "\r\n",
        "  output_layer_activation = np.dot(hidden_layer_output, output_wts)\r\n",
        "  output_layer_activation += output_bias\r\n",
        "  predicted_output = sigmoid(output_layer_activation)\r\n",
        "\r\n",
        "  #BackPropagation\r\n",
        "  error = expected_output - predicted_output\r\n",
        "  d_predicted_output = error * sigmoid_derivative(predicted_output)\r\n",
        "\r\n",
        "  error_hidden_layer = d_predicted_output.dot(output_wts.T)\r\n",
        "  d_hidden_layer = error_hidden_layer * sigmoid_derivative(predicted_output)\r\n",
        "\r\n",
        "  #Updating Weights and Biases\r\n",
        "  output_wts += hidden_layer_output.T.dot(d_predicted_output) * lr \r\n",
        "  output_bias += np.sum(d_predicted_output, axis = 0, keepdims = True ) * lr \r\n",
        "  hidden_wts += inputs.T.dot(d_hidden_layer) * lr\r\n",
        "  hidden_bias += np.sum(d_hidden_layer, axis = 0, keepdims=True) * lr \r\n",
        "\r\n",
        "print(\"Final Hidden weights: \", end='')\r\n",
        "print(*hidden_wts)\r\n",
        "print(\"Final Hidden bias: \", end='')\r\n",
        "print(*hidden_bias)\r\n",
        "print(\"Final Output weights: \", end='')\r\n",
        "print(*output_wts)\r\n",
        "print(\"Final Output bias: \", end='')\r\n",
        "print(*output_bias)\r\n",
        "\r\n",
        "print(\"\\n Output from Neural Network after all epochs : \", end='')\r\n",
        "print(*predicted_output)\r\n",
        "\r\n",
        "end_time=time.time()\r\n",
        "training_time= end_time - start_time\r\n",
        "print(\"Time to for training is:\", training_time)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Hidden weights: [ 0.11401304 -0.22425108] [ 0.22175059 -0.43216644]\n",
            "Final Hidden bias: [0.37656963 0.32268138]\n",
            "Final Output weights: [1.84569258] [0.88157458]\n",
            "Final Output bias: [-1.60651478]\n",
            "\n",
            " Output from Neural Network after all epochs : [0.49983959] [0.50028513] [0.50018193] [0.49992498]\n",
            "Time to for training is: 1.1127822399139404\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}